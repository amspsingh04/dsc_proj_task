{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential, load_model\nfrom tensorflow.keras.layers import Dense, Embedding, GlobalAveragePooling1D\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nimport pickle\nimport pandas as pd\nVOCAB_SIZE = 10000\nMAX_LEN = 250\nEMBEDDING_DIM = 16\nMODEL_PATH = 'sentiment_analysis_model.h5'\ndata = pd.read_csv('/kaggle/input/sentiment140/training.1600000.processed.noemoticon.csv', encoding='latin-1')\ndf_shuffled = data.sample(frac=1).reset_index(drop=True)\ntexts = []\nlabels = []\nfor _, row in df_shuffled.iterrows():\n    texts.append(row[-1])\n    label = row[0]\n    labels.append(0 if label == 0 else 1 if label == 2 else 2)\ntexts = np.array(texts)\nlabels = np.array(labels)\ntokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=VOCAB_SIZE)\ntokenizer.fit_on_texts(texts)\nsequences = tokenizer.texts_to_sequences(texts)\npadded_sequences = pad_sequences(sequences, maxlen=MAX_LEN, value=VOCAB_SIZE-1, padding='post')\nwith open('tokenizer.pickle', 'wb') as handle:\n    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\ntrain_data = padded_sequences[:-1500]\ntest_data = padded_sequences[-1500:]\ntrain_labels = labels[:-1500]\ntest_labels = labels[-1500:]\nif os.path.exists(MODEL_PATH):\n    print(\"Loading saved model...\")\n    model = load_model(MODEL_PATH)\nelse:\n    print(\"Training a new model...\")\n    model = Sequential([\n        Embedding(VOCAB_SIZE, EMBEDDING_DIM, input_length=MAX_LEN),\n        GlobalAveragePooling1D(),\n        Dense(16, activation='relu'),\n        Dense(3, activation='softmax')  \n    ])\n    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n    model.fit(train_data, train_labels, epochs=15, batch_size=32, validation_split=0.2)\n    model.save(MODEL_PATH)\nloss, accuracy = model.evaluate(test_data, test_labels)\nprint(f\"Test accuracy: {accuracy * 100:.2f}%\")\ndef encode_text(text):\n    tokens = tf.keras.preprocessing.text.text_to_word_sequence(text)\n    tokens = [tokenizer.word_index[word] if word in tokenizer.word_index else 0 for word in tokens]\n    return pad_sequences([tokens], maxlen=MAX_LEN, padding='post', value=VOCAB_SIZE-1)\nwhile True:\n    user_input = input(\"Enter a sentence for sentiment analysis (or 'exit' to quit): \")\n    if user_input.lower() == 'exit':\n        break\n    encoded_input = encode_text(user_input)\n    prediction = np.argmax(model.predict(encoded_input))\n    if prediction == 0:\n        print(\"Sentiment: Negative\")\n    elif prediction == 1:\n        print(\"Sentiment: Neutral\")\n    else:\n        print(\"Sentiment: Positive\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-06-22T14:00:16.498455Z","iopub.execute_input":"2024-06-22T14:00:16.498784Z","iopub.status.idle":"2024-06-22T15:04:46.502269Z","shell.execute_reply.started":"2024-06-22T14:00:16.498761Z","shell.execute_reply":"2024-06-22T15:04:46.500992Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_33/3552908567.py:18: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  texts.append(row[-1])\n/tmp/ipykernel_33/3552908567.py:19: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  label = row[0]\n","output_type":"stream"},{"name":"stdout","text":"Training a new model...\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/15\n\u001b[1m39963/39963\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 4ms/step - accuracy: 0.6744 - loss: 0.5831 - val_accuracy: 0.7434 - val_loss: 0.5156\nEpoch 2/15\n\u001b[1m39963/39963\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 4ms/step - accuracy: 0.7743 - loss: 0.4761 - val_accuracy: 0.7906 - val_loss: 0.4468\nEpoch 3/15\n\u001b[1m39963/39963\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 4ms/step - accuracy: 0.7834 - loss: 0.4591 - val_accuracy: 0.7819 - val_loss: 0.4580\nEpoch 4/15\n\u001b[1m39963/39963\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 4ms/step - accuracy: 0.7874 - loss: 0.4523 - val_accuracy: 0.7985 - val_loss: 0.4424\nEpoch 5/15\n\u001b[1m39963/39963\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 4ms/step - accuracy: 0.7899 - loss: 0.4477 - val_accuracy: 0.7982 - val_loss: 0.4363\nEpoch 6/15\n\u001b[1m39963/39963\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 4ms/step - accuracy: 0.7929 - loss: 0.4415 - val_accuracy: 0.7876 - val_loss: 0.4485\nEpoch 7/15\n\u001b[1m39963/39963\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 4ms/step - accuracy: 0.7938 - loss: 0.4406 - val_accuracy: 0.8015 - val_loss: 0.4293\nEpoch 8/15\n\u001b[1m39963/39963\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 4ms/step - accuracy: 0.7958 - loss: 0.4375 - val_accuracy: 0.7690 - val_loss: 0.4740\nEpoch 9/15\n\u001b[1m39963/39963\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 4ms/step - accuracy: 0.7964 - loss: 0.4360 - val_accuracy: 0.7997 - val_loss: 0.4316\nEpoch 10/15\n\u001b[1m39963/39963\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 4ms/step - accuracy: 0.7989 - loss: 0.4333 - val_accuracy: 0.8007 - val_loss: 0.4329\nEpoch 11/15\n\u001b[1m39963/39963\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 4ms/step - accuracy: 0.7987 - loss: 0.4323 - val_accuracy: 0.7976 - val_loss: 0.4369\nEpoch 12/15\n\u001b[1m39963/39963\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 4ms/step - accuracy: 0.8002 - loss: 0.4309 - val_accuracy: 0.8011 - val_loss: 0.4297\nEpoch 13/15\n\u001b[1m39963/39963\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 3ms/step - accuracy: 0.8005 - loss: 0.4301 - val_accuracy: 0.7936 - val_loss: 0.4416\nEpoch 14/15\n\u001b[1m39963/39963\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 4ms/step - accuracy: 0.8019 - loss: 0.4285 - val_accuracy: 0.8031 - val_loss: 0.4320\nEpoch 15/15\n\u001b[1m39963/39963\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 3ms/step - accuracy: 0.8032 - loss: 0.4259 - val_accuracy: 0.7798 - val_loss: 0.4603\n\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7754 - loss: 0.4623\nTest accuracy: 77.87%\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Enter a sentence for sentiment analysis (or 'exit' to quit):  test\n"},{"name":"stdout","text":"\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step\nSentiment: Negative\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Enter a sentence for sentiment analysis (or 'exit' to quit):  bye\n"},{"name":"stdout","text":"\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\nSentiment: Negative\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Enter a sentence for sentiment analysis (or 'exit' to quit):  hello\n"},{"name":"stdout","text":"\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\nSentiment: Neutral\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Enter a sentence for sentiment analysis (or 'exit' to quit):  im good\n"},{"name":"stdout","text":"\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\nSentiment: Neutral\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Enter a sentence for sentiment analysis (or 'exit' to quit):  im happy\n"},{"name":"stdout","text":"\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\nSentiment: Neutral\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Enter a sentence for sentiment analysis (or 'exit' to quit):  im so happy today is a good day\n"},{"name":"stdout","text":"\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\nSentiment: Neutral\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Enter a sentence for sentiment analysis (or 'exit' to quit):  exit\n"}]}]}